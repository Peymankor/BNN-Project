{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import collections\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_hidden_layers\":2,\n",
    "    \"num_hidden_units\":400,\n",
    "    \"batch_size\":128,\n",
    "    \"epochs\":10,\n",
    "    \"learning_rate\":0.001,\n",
    "    \"num_samples\":1,\n",
    "    \"pi\":0.25,\n",
    "    \"sigma_p\":1.0,\n",
    "    \"sigma_p1\":0.75,\n",
    "    \"sigma_p2\":0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data, label):\n",
    "    return data.astype(np.float32)/126.0, label.astype(np.float32)\n",
    "\n",
    "mnist = mx.test_utils.get_mnist()\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "batch_size = config['batch_size']\n",
    "train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=True, transform=transform),\n",
    "                                      batch_size, shuffle=True)\n",
    "test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                                     batch_size, shuffle=False)\n",
    "\n",
    "num_train = sum([batch_size for i in train_data])\n",
    "num_batches = num_train/ batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return nd.maximum(X, nd.zeros_like(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = config['num_hidden_layers']\n",
    "\n",
    "# define function for evaluating MLP\n",
    "def net(X, layer_params):\n",
    "    layer_input = X\n",
    "    for i in range(len(layer_params) // 2 - 2):\n",
    "        h_linear = nd.dot(layer_input, layer_params[2*i]) + layer_params[2*i + 1]\n",
    "        layer_input = relu(h_linear)\n",
    "    # last layer without ReLU\n",
    "    output = nd.dot(layer_input, layer_params[-2]) + layer_params[-1]\n",
    "    return output\n",
    "\n",
    "# define network weight shapes\n",
    "layer_param_shapes = []\n",
    "num_hidden = config['num_hidden_units']\n",
    "for i in range(num_layers + 1):\n",
    "    if i == 0: # input layer\n",
    "        W_shape = (num_inputs, num_hidden)\n",
    "        b_shape = (num_hidden,)\n",
    "    elif i == num_layers: # last layer\n",
    "        W_shape = (num_hidden, num_outputs)\n",
    "        b_shape = (num_outputs,)\n",
    "    else: # hidden layers\n",
    "        W_shape = (num_hidden, num_hidden)\n",
    "        b_shape = (num_hidden,)\n",
    "    layer_param_shapes.extend([W_shape, b_shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax_likelihood(yhat_linear, y):\n",
    "    return nd.nansum(y * nd.log_softmax(yhat_linear), axis=0, exclude=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG2PI = np.log(2*np.pi)\n",
    "\n",
    "def log_gaussian(x, mu, sigma):\n",
    "    return -0.5* LOG2PI - nd.log(sigma) - (x-mu)**2 / (2*sigma **2)\n",
    "\n",
    "def gaussian_prior(x):\n",
    "    sigma_p = nd.array([config['sigma_p']], ctx=ctx)\n",
    "    \n",
    "    return nd.sum(log_gaussian(x,0,sigma_p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sigma):\n",
    "\n",
    "    scaling = 1.0 / nd.sqrt(2.0 * np.pi * (sigma ** 2))\n",
    "    bell = nd.exp(- (x - mu) ** 2 / (2.0 * sigma ** 2))\n",
    "\n",
    "    return scaling * bell\n",
    "\n",
    "def scale_mixture_prior(x):\n",
    "    sigma_p1 = nd.array([config['sigma_p1']], ctx=ctx)\n",
    "    sigma_p2 = nd.array([config['sigma_p2']], ctx=ctx)\n",
    "    pi = config['pi']\n",
    "\n",
    "    first_gaussian = pi * gaussian(x, 0., sigma_p1)\n",
    "    second_gaussian = (1 - pi) * gaussian(x, 0., sigma_p2)\n",
    "\n",
    "    return nd.log(first_gaussian + second_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(output, label_one_hot, params, mus, sigmas, log_prior, log_likelihood):\n",
    "\n",
    "    # Calculate data likelihood\n",
    "    log_likelihood_sum = nd.sum(log_likelihood(output, label_one_hot))\n",
    "\n",
    "    # Calculate prior\n",
    "    log_prior_sum = sum([nd.sum(log_prior(param)) for param in params])\n",
    "\n",
    "    # Calculate variational posterior\n",
    "    log_var_posterior_sum = sum([nd.sum(log_gaussian(params[i], mus[i], sigmas[i])) for i in range(len(params))])\n",
    "\n",
    "    # Calculate total loss\n",
    "    return 1.0 / num_batches * (log_var_posterior_sum - log_prior_sum) - log_likelihood_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net, layer_params):\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(data, layer_params)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        numerator += nd.sum(predictions == label)\n",
    "        denominator += data.shape[0]\n",
    "    return (numerator / denominator).asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_scale = .1\n",
    "rho_offset = -3\n",
    "\n",
    "# initialize variational parameters; mean and variance for each weight\n",
    "mus = []\n",
    "rhos = []\n",
    "\n",
    "for shape in layer_param_shapes:\n",
    "    mu = nd.random_normal(shape=shape, ctx=ctx, scale=weight_scale)\n",
    "    rho = rho_offset + nd.zeros(shape=shape, ctx=ctx)\n",
    "    mus.append(mu)\n",
    "    rhos.append(rho)\n",
    "\n",
    "variational_params = mus + rhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in variational_params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_epsilons(param_shapes):\n",
    "    epsilons = [nd.random_normal(shape=shape, loc=0., scale=1.0, ctx=ctx) for shape in param_shapes]\n",
    "    return epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    return nd.log(1. + nd.exp(x))\n",
    "\n",
    "def transform_rhos(rhos):\n",
    "    return [softplus(rho) for rho in rhos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_gaussian_samples(mus, sigmas, epsilons):\n",
    "    samples = []\n",
    "    for j in range(len(mus)):\n",
    "        samples.append(mus[j] + sigmas[j] * epsilons[j])\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 2626.558530731976, Train_acc 0.9427, Test_acc 0.9474\n",
      "Epoch 1. Loss: 2606.8084283395356, Train_acc 0.9615333, Test_acc 0.9607\n",
      "Epoch 2. Loss: 2600.661865940786, Train_acc 0.9687, Test_acc 0.9659\n",
      "Epoch 3. Loss: 2595.136452222671, Train_acc 0.9730833, Test_acc 0.9694\n",
      "Epoch 4. Loss: 2593.2551951487094, Train_acc 0.97655, Test_acc 0.9711\n",
      "Epoch 5. Loss: 2590.533947345753, Train_acc 0.97943336, Test_acc 0.9744\n",
      "Epoch 6. Loss: 2588.444435875844, Train_acc 0.98263335, Test_acc 0.9756\n",
      "Epoch 7. Loss: 2585.5413791178544, Train_acc 0.984, Test_acc 0.9765\n",
      "Epoch 8. Loss: 2583.805116739097, Train_acc 0.9855, Test_acc 0.9778\n",
      "Epoch 9. Loss: 2582.552079515809, Train_acc 0.9866167, Test_acc 0.9776\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = config['epochs']\n",
    "learning_rate = config['learning_rate']\n",
    "smoothing_constant = .01\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(ctx)\n",
    "        label_one_hot = nd.one_hot(label, 10)\n",
    "\n",
    "        with autograd.record():\n",
    "            # sample epsilons from standard normal\n",
    "            epsilons = sample_epsilons(layer_param_shapes)\n",
    "\n",
    "            # compute softplus for variance\n",
    "            sigmas = transform_rhos(rhos)\n",
    "\n",
    "            # obtain a sample from q(w|theta) by transforming the epsilons\n",
    "            layer_params = transform_gaussian_samples(mus, sigmas, epsilons)\n",
    "\n",
    "            # forward-propagate the batch\n",
    "            output = net(data, layer_params)\n",
    "\n",
    "            # calculate the loss\n",
    "            loss = combined_loss(output, label_one_hot, layer_params, mus, sigmas, gaussian_prior, log_softmax_likelihood)\n",
    "\n",
    "        # backpropagate for gradient calculation\n",
    "        loss.backward()\n",
    "\n",
    "        # apply stochastic gradient descent to variational parameters\n",
    "        SGD(variational_params, learning_rate)\n",
    "\n",
    "        # calculate moving loss for monitoring convergence\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (curr_loss if ((i == 0) and (e == 0))\n",
    "                       else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_data, net, mus)\n",
    "    train_accuracy = evaluate_accuracy(train_data, net, mus)\n",
    "    train_acc.append(np.asscalar(train_accuracy))\n",
    "    test_acc.append(np.asscalar(test_accuracy))\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" %\n",
    "          (e, moving_loss, train_accuracy, test_accuracy))\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
